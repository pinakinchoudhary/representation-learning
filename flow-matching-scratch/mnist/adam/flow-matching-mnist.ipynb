{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2952682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 469/469 [00:51<00:00,  9.03it/s, Loss=144.0164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training visualization samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  47%|████▋     | 220/469 [00:24<00:27,  8.94it/s, Loss=46.2330]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchdiffeq import odeint\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================== Configuration Parameters ==================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 28\n",
    "channels = 1\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "epochs = 100\n",
    "num_classes = 10\n",
    "model_save_path = 'FMmodel.pth'\n",
    "\n",
    "# ================== Data Loading ==================\n",
    "\n",
    "# Normalize image to [-1,1]\n",
    "def normalize_img(x):\n",
    "    return 2 * x - 1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),              # Convert image to tensor\n",
    "    transforms.Lambda(normalize_img)    # Apply normalization\n",
    "])\n",
    "\n",
    "# ================== Model Architecture ==================\n",
    "class ConditionedDoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution module with condition injection\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, cond_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.GroupNorm(8, out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels + cond_dim, out_channels, kernel_size=3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(8, out_channels)\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        x = F.silu(self.norm1(self.conv1(x)))\n",
    "        cond = cond.expand(-1, -1, x.size(2), x.size(3))  # Dynamic condition broadcasting\n",
    "        x = torch.cat([x, cond], dim=1)\n",
    "        return F.silu(self.norm2(self.conv2(x)))\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downsampling module\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, cond_dim):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.conv = ConditionedDoubleConv(in_channels, out_channels, cond_dim)\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        x = self.maxpool(x)\n",
    "        return self.conv(x, cond)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling module\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, cond_dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = ConditionedDoubleConv(in_channels, out_channels, cond_dim)\n",
    "\n",
    "    def forward(self, x1, x2, cond):\n",
    "        x1 = self.up(x1)\n",
    "        # Size alignment\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x, cond)\n",
    "\n",
    "\n",
    "class ConditionalUNet(nn.Module):\n",
    "    \"\"\"Dimension-safe conditional UNet\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Unified condition encoding dimensions\n",
    "        self.t_dim = 16\n",
    "        self.label_dim = 16\n",
    "        self.cond_dim = self.t_dim + self.label_dim  # 32\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, self.t_dim)\n",
    "        )\n",
    "        # Label embedding\n",
    "        self.label_embed = nn.Embedding(num_classes, self.label_dim)\n",
    "\n",
    "        # Encoder path\n",
    "        self.inc = ConditionedDoubleConv(1, 64, self.cond_dim)\n",
    "        self.down1 = Down(64, 128, self.cond_dim)\n",
    "        self.down2 = Down(128, 256, self.cond_dim)\n",
    "\n",
    "        # Decoder path\n",
    "        self.up1 = Up(256 + 128, 128, self.cond_dim)  # Input channel correction\n",
    "        self.up2 = Up(128 + 64, 64, self.cond_dim)\n",
    "        self.outc = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, t, labels):\n",
    "        # Condition encoding (unified dimensions)\n",
    "        t_emb = self.time_embed(t.view(-1, 1))  # [B, 16]\n",
    "        lbl_emb = self.label_embed(labels)  # [B, 16]\n",
    "        cond = torch.cat([t_emb, lbl_emb], dim=1)  # [B, 32]\n",
    "        cond = cond.unsqueeze(-1).unsqueeze(-1)  # [B, 32, 1, 1]\n",
    "\n",
    "        # Encoder\n",
    "        x1 = self.inc(x, cond)\n",
    "        x2 = self.down1(x1, cond)\n",
    "        x3 = self.down2(x2, cond)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up1(x3, x2, cond)\n",
    "        x = self.up2(x, x1, cond)\n",
    "        return self.outc(x)\n",
    "\n",
    "\n",
    "# ================== Training and Generation ==================\n",
    "# Initialize model and optimizer here for global access (especially for generate_with_label)\n",
    "model = ConditionalUNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_with_label(label, num_samples=16):\n",
    "    \"\"\"\n",
    "    Generate samples with specified label.\n",
    "    Args:\n",
    "        label (int): Digit label to generate (0-9).\n",
    "        num_samples (int): Number of samples to generate.\n",
    "    Returns:\n",
    "        torch.Tensor: Generated image tensor, shape (num_samples, image_size, image_size), values in [0, 1].\n",
    "    \"\"\"\n",
    "    # Save current model training state and set to eval mode\n",
    "    current_model_state = model.training\n",
    "    model.eval()\n",
    "\n",
    "    # Create initial noise and label tensors\n",
    "    x0 = torch.randn(num_samples, 1, image_size, image_size, device=device)\n",
    "    labels = torch.full((num_samples,), label, device=device, dtype=torch.long)\n",
    "\n",
    "    # ODE: t is time, x is current state\n",
    "    def ode_func(t: torch.Tensor, x: torch.Tensor):\n",
    "        t_expanded = t.expand(x.size(0))  # [1] -> [num_samples]\n",
    "        vt = model(x, t_expanded, labels)  # Predict velocity field\n",
    "        return vt\n",
    "\n",
    "    # Time points: 0 -> 1\n",
    "    t_eval = torch.tensor([0.0, 1.0], device=device)\n",
    "\n",
    "    # Solve ODE (adaptive step size)\n",
    "    generated = odeint(\n",
    "        ode_func,\n",
    "        x0,\n",
    "        t_eval,\n",
    "        rtol=1e-5,\n",
    "        atol=1e-5,\n",
    "        method='dopri5'\n",
    "    )\n",
    "\n",
    "    # Restore training state\n",
    "    model.train(current_model_state)\n",
    "\n",
    "    # Post-processing\n",
    "    images = (generated[-1].clamp(-1, 1) + 1) / 2  # [-1,1] -> [0,1]\n",
    "    return images.cpu().squeeze(1)\n",
    "\n",
    "\n",
    "def visualize_train(epoch):\n",
    "    \"\"\"\n",
    "    Generate visualization using current model:\n",
    "    Create a 10x10 grid with columns 1-10 for each digit (0-9),\n",
    "    generating 10 images per digit with labels in the first row.\n",
    "    \"\"\"\n",
    "    print(\"Generating training visualization samples...\")\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)  # Reduce subplot spacing\n",
    "\n",
    "    # Generate 10 images for each digit 0-9\n",
    "    for label in range(num_classes):\n",
    "        # Generate 10 samples for current digit\n",
    "        generated_images = generate_with_label(\n",
    "            label=label,\n",
    "            num_samples=10\n",
    "        ).numpy()  # Shape (10, 28, 28)\n",
    "\n",
    "        # Plot in current column, ensuring each column represents one digit\n",
    "        for i in range(10):\n",
    "            # Subplot position calculation: (row_index * total_columns) + column_index + 1\n",
    "            # We want column 0 for digit 0, column 1 for digit 1, etc.\n",
    "            # So: (row i * num_classes (10)) + column label + 1\n",
    "            ax = plt.subplot(10, num_classes, (i * num_classes) + label + 1)\n",
    "            plt.imshow(generated_images[i], cmap='gray', vmin=0, vmax=1)\n",
    "            ax.axis('off')\n",
    "            # Add digit label in first row of each column (when i == 0)\n",
    "            if i == 0:\n",
    "                ax.set_title(str(label), fontsize=16, pad=5)  # set_title is more appropriate\n",
    "    plt.suptitle(\"Generated Samples During Training\", fontsize=20, y=0.97)\n",
    "    plt.savefig(f\"epoch{epoch}.jpg\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def hundred_image(model_path=model_save_path, num_sample=5):\n",
    "    print(f\"Loading model from {model_path} and generating {num_sample} images...\")\n",
    "    # Create new model instance and load weights\n",
    "    global model\n",
    "    original_model = model  # Save original model reference\n",
    "\n",
    "    loaded_model = ConditionalUNet().to(device)\n",
    "    if os.path.exists(model_path):\n",
    "        loaded_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        loaded_model.eval()  # Evaluation mode\n",
    "    else:\n",
    "        print(f\"Error: Model file not found: {model_path}. Cannot generate images.\")\n",
    "        return\n",
    "\n",
    "    model = loaded_model  # Temporarily replace global model with loaded model\n",
    "\n",
    "    for k in range(num_sample):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        print(f\"Generating image {k + 1}...\")\n",
    "        for label in tqdm(range(num_classes), desc=\"Generating images for each digit\"):\n",
    "            # Generate 10 samples for current digit\n",
    "            generated_images = generate_with_label(\n",
    "                label=label,\n",
    "                num_samples=10\n",
    "            ).numpy()  # Shape (10, 28, 28)\n",
    "\n",
    "            # Plot in current column\n",
    "            for i in range(10):\n",
    "                ax = plt.subplot(10, num_classes, (i * num_classes) + label + 1)\n",
    "                plt.imshow(generated_images[i], cmap='gray', vmin=0, vmax=1)\n",
    "                ax.axis('off')\n",
    "                # Add label in first row\n",
    "                if i == 0:\n",
    "                    ax.set_title(str(label), fontsize=16, pad=5)\n",
    "\n",
    "        plt.suptitle(f\"Final Generated Samples (Generation {k + 1})\", fontsize=20, y=0.97)\n",
    "        plt.savefig(f\"generated_image{k + 1}.jpg\")\n",
    "        print(f\"Generated image saved to: generated_image{k + 1}.jpg\")\n",
    "        plt.close()\n",
    "\n",
    "    # Restore global model reference\n",
    "    model = original_model\n",
    "\n",
    "\n",
    "def train(num_epochs=100):\n",
    "    \"\"\"Training loop\"\"\"\n",
    "    print(\"Starting training...\")\n",
    "    # Ensure train_loader is available here since it's initialized in the if __name__ == \"__main__\": block\n",
    "    global train_loader\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Use tqdm to show training progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "        model.train()  # Training mode\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in progress_bar:  # Add progress bar\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Dynamic noise generation\n",
    "            noise = torch.randn_like(images)\n",
    "            t = torch.rand(images.size(0), device=device)\n",
    "            # Flow Matching target velocity is the velocity field from noise x0 to real data x1\n",
    "            # x_t = (1-t) * x0 + t * x1\n",
    "            xt = (1 - t.view(-1, 1, 1, 1)) * noise + t.view(-1, 1, 1, 1) * images\n",
    "\n",
    "            # Forward pass, model predicts velocity field v_t\n",
    "            vt_pred = model(xt, t, labels)\n",
    "            # True velocity field v_t = x1 - x0\n",
    "            loss = F.mse_loss(vt_pred, images - noise)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to prevent explosion\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress bar with loss display\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{total_loss:.4f}\"})\n",
    "\n",
    "        # Generate samples every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            visualize_train(epoch + 1)\n",
    "        # Generate sample for first epoch\n",
    "        if epoch == 0:\n",
    "            visualize_train(epoch + 1)\n",
    "\n",
    "    # Save model after training\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Training complete. Model saved to: {model_save_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=2)\n",
    "    # Comment out when using existing model\n",
    "    train(epochs)\n",
    "    hundred_image(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
