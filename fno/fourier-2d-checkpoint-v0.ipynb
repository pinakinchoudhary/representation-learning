{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e667281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pinakinchoudhary/dev/myenv/lib/python3.10/site-packages/torch/cuda/__init__.py:829: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "from utilities3 import *\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d78079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816aa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2,  width):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_list = []\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = F.pad(x, [0,self.padding, 0,self.padding])\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        if not self.training:\n",
    "            x_list.append(x[..., :-self.padding, :-self.padding].detach().clone())\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        if not self.training:\n",
    "            x_list.append(x[..., :-self.padding, :-self.padding].detach().clone())\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        if not self.training:\n",
    "            x_list.append(x[..., :-self.padding, :-self.padding].detach().clone())\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x[..., :-self.padding, :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if not self.training:\n",
    "            for i in range(len(x_list)):\n",
    "                x_list[i] = x_list[i].permute(0, 2, 3, 1)\n",
    "                x_list[i] = self.fc1(x_list[i])\n",
    "                x_list[i] = F.gelu(x_list[i])\n",
    "                x_list[i] = self.fc2(x_list[i])\n",
    "\n",
    "        return x, x_list\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298edc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'darcy/piececonst_r421_N1024_smooth1.mat'\n",
    "TEST_PATH = 'darcy/piececonst_r421_N1024_smooth2.mat'\n",
    "\n",
    "ntrain = 1000\n",
    "ntest = 100\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 10\n",
    "step_size = 100\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 12\n",
    "width = 32\n",
    "\n",
    "r = 5\n",
    "h = int(((421 - 1)/r) + 1)\n",
    "s = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966762e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = MatReader(TRAIN_PATH)\n",
    "x_train = reader.read_field('coeff')[:ntrain,::r,::r][:,:s,:s]\n",
    "y_train = reader.read_field('sol')[:ntrain,::r,::r][:,:s,:s]\n",
    "\n",
    "reader.load_file(TEST_PATH)\n",
    "x_test = reader.read_field('coeff')[:ntest,::r,::r][:,:s,:s]\n",
    "y_test = reader.read_field('sol')[:ntest,::r,::r][:,:s,:s]\n",
    "\n",
    "x_normalizer = UnitGaussianNormalizer(x_train)\n",
    "x_train = x_normalizer.encode(x_train)\n",
    "x_test = x_normalizer.encode(x_test)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(y_train)\n",
    "y_train = y_normalizer.encode(y_train)\n",
    "\n",
    "x_train = x_train.reshape(ntrain,s,s,1)\n",
    "x_test = x_test.reshape(ntest,s,s,1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d24d3ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188353\n",
      "Epoch 0: Time 1.66s, Train L2 Loss: 0.1623, Intermediate losses: [10.300284423828124, 7.337637939453125, 5.276469116210937], Test L2 Loss: 0.1143\n",
      "Epoch 1: Time 1.66s, Train L2 Loss: 0.1023, Intermediate losses: [11.0690283203125, 7.506444702148437, 5.172318115234375], Test L2 Loss: 0.0939\n",
      "Epoch 2: Time 1.65s, Train L2 Loss: 0.0734, Intermediate losses: [13.160272216796875, 8.71386474609375, 4.341381225585938], Test L2 Loss: 0.0612\n",
      "Epoch 3: Time 1.66s, Train L2 Loss: 0.0534, Intermediate losses: [14.053746337890624, 9.61626220703125, 4.223255615234375], Test L2 Loss: 0.0489\n",
      "Epoch 4: Time 1.66s, Train L2 Loss: 0.0428, Intermediate losses: [14.73343505859375, 10.5700244140625, 4.071277160644531], Test L2 Loss: 0.0398\n",
      "Epoch 5: Time 1.66s, Train L2 Loss: 0.0361, Intermediate losses: [15.15748291015625, 10.9986181640625, 3.8894854736328126], Test L2 Loss: 0.0373\n",
      "Epoch 6: Time 1.66s, Train L2 Loss: 0.0316, Intermediate losses: [15.77085693359375, 11.419732666015625, 4.115193786621094], Test L2 Loss: 0.0326\n",
      "Epoch 7: Time 1.66s, Train L2 Loss: 0.0272, Intermediate losses: [16.16239501953125, 11.65583984375, 4.145647583007812], Test L2 Loss: 0.0295\n",
      "Epoch 8: Time 1.71s, Train L2 Loss: 0.0248, Intermediate losses: [16.615799560546876, 11.76314208984375, 4.222555541992188], Test L2 Loss: 0.0262\n",
      "Epoch 9: Time 1.68s, Train L2 Loss: 0.0229, Intermediate losses: [17.0825439453125, 12.03797119140625, 4.183421630859375], Test L2 Loss: 0.0305\n"
     ]
    }
   ],
   "source": [
    "model = FNO2d(modes, modes, width).cuda()\n",
    "print(count_params(model))\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "y_normalizer.cuda()\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out, _ = model(x)\n",
    "        out = out.reshape(batch_size, s, s)\n",
    "        out = y_normalizer.decode(out)\n",
    "        y = y_normalizer.decode(y)\n",
    "\n",
    "        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            out, out_list = model(x)\n",
    "            out = out.reshape(batch_size, s, s)\n",
    "            out = y_normalizer.decode(out)\n",
    "\n",
    "            test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "            for out in out_list:\n",
    "                out = out.reshape(batch_size, s, s)\n",
    "                out = y_normalizer.decode(out)\n",
    "            test_l2_list = [myloss(o.view(batch_size, -1), y.view(batch_size,-1)).item() for o in out_list]\n",
    "\n",
    "    train_l2/= ntrain\n",
    "    test_l2 /= ntest\n",
    "    test_l2_list = [tl / ntest for tl in test_l2_list]\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(f'Epoch {ep}: Time {t2-t1:.2f}s, Train L2 Loss: {train_l2:.4f}, Intermediate losses: {test_l2_list}, Test L2 Loss: {test_l2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a9d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
